{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 讀檔\n",
    "TotalQueryPath = 'C:/Users/dnc22/IR_HW2/query_list.txt'\n",
    "TotalDocumentPath = 'C:/Users/dnc22/IR_HW2/doc_list.txt'\n",
    "QuerysPath = 'C:/Users/dnc22/IR_HW2/queries/'\n",
    "DocumentsPath = 'C:/Users/dnc22/IR_HW2/docs/'\n",
    "\n",
    "# Document_dict =\n",
    "# {\n",
    "#     'FBIS3-10082' = ['languag','f','p','105','spanish' ...]\n",
    "#     ...\n",
    "# }\n",
    "\n",
    "# Document_Count = \n",
    "# {\n",
    "#     dict:'FBIS3-10082' = \n",
    "#     {\n",
    "#         'languag' = 2,\n",
    "#         'f' = 1,\n",
    "#         'p' = 1,\n",
    "#         ...\n",
    "#         'de' = 6,\n",
    "#         ...\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# Variable_AvgWord          5000篇 Document 的平均字數\n",
    "\n",
    "Query_dict = {}\n",
    "Document_Count = {}\n",
    "Variable_AvgWord = 0\n",
    "\n",
    "QuerySet = []\n",
    "\n",
    "with open (TotalQueryPath, 'r') as f:\n",
    "    for QueryFileName in f.readlines():\n",
    "        QueryFileName = QueryFileName.strip('\\n')\n",
    "\n",
    "        with open(QuerysPath + QueryFileName + '.txt', 'r') as qf:\n",
    "            query_list = []\n",
    "            for query_read in qf.readlines():\n",
    "                for word in query_read.split(' '):\n",
    "                    word = word.lower()\n",
    "                    query_list.append(word)\n",
    "                    QuerySet.append(word)\n",
    "\n",
    "            #print(QueryFileName, query_list)\n",
    "            Query_dict[QueryFileName] = query_list\n",
    "#print(Query_dict)\n",
    "#print(QuerySet)\n",
    "\n",
    "Document_dict = {}\n",
    "with open (TotalDocumentPath, 'r') as f:\n",
    "    for DocumentFileName in f.readlines():\n",
    "        DocumentFileName = DocumentFileName.strip('\\n')\n",
    "\n",
    "        with open(DocumentsPath + DocumentFileName + '.txt', 'r') as df:\n",
    "            document_list = []\n",
    "            for document_read in df.readlines():\n",
    "                for word in document_read.split(' '):\n",
    "                    word = word.lower()\n",
    "                    if word in QuerySet:\n",
    "                        document_list.append(word)\n",
    "\n",
    "            #print(QueryFileName, query_list)\n",
    "            dcount = {}\n",
    "            Variable_AvgWord += len(document_list)\n",
    "\n",
    "            for word in document_list:\n",
    "                dcount[word] = dcount.get(word,0) + 1\n",
    "\n",
    "            Document_dict[DocumentFileName] = document_list\n",
    "            Document_Count[DocumentFileName] = dcount\n",
    "\n",
    "Variable_AvgWord /= len(Document_dict)\n",
    "\n",
    "#print(Document_dict)\n",
    "#print(Document_Count)\n",
    "#print(Variable_AvgWord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 計算 TF\n",
    "import math\n",
    "\n",
    "# Query_TF = \n",
    "# {\n",
    "#     '301' = \n",
    "#     {\n",
    "#         'intern' = 0.33333 ,\n",
    "#         'organ' = 0.33333 ,\n",
    "#         'crime' = 0.33333 \n",
    "#     }\n",
    "#     ...\n",
    "# }\n",
    "\n",
    "# Word_Count =                              # 計算Query出現在全部的 Document 幾次(一篇最多一次), 用來計算IDF\n",
    "# {\n",
    "#     'intern': 52次\n",
    "#     'organ': 38次\n",
    "#     ...\n",
    "# }\n",
    "\n",
    "Query_TF = {}\n",
    "Word_Count = {}\n",
    "for QueryDict in Query_dict:\n",
    "    FileName = QueryDict\n",
    "    #print(FileName, len(Query_dict[FileName]))\n",
    "    qdict = {}\n",
    "    for word in Query_dict[FileName]:       # 先計算出現幾次\n",
    "        if word not in qdict:\n",
    "            qdict[word] = 1\n",
    "            Word_Count[word] = 0            # Query重複出現, 不重複計算\n",
    "        else:\n",
    "            qdict[word] += 1\n",
    "    \n",
    "    for word in qdict:                      # 最後直接一次除以整篇文章出現的次數去算頻率\n",
    "        #qdict[word] = qdict[word] / len(Query_dict[FileName])\n",
    "        qdict[word] = qdict[word]\n",
    "\n",
    "    Query_TF[FileName] = qdict\n",
    "\n",
    "#print(Query_TF)\n",
    "\n",
    "# document TF\n",
    "Document_TF = {}\n",
    "for DocumentDict in Document_dict:\n",
    "    FileName = DocumentDict\n",
    "    ddict = {}\n",
    "    wordSet = []        \n",
    "\n",
    "    for word in Document_dict[FileName]:\n",
    "        if word not in ddict:\n",
    "            ddict[word] = 1\n",
    "        else:\n",
    "            ddict[word] += 1\n",
    "        \n",
    "        if word not in wordSet:\n",
    "            if word in Word_Count:\n",
    "                Word_Count[word] += 1           # 計算 query 在這篇 document 有沒有出現過\n",
    "                                                # 條件: 必須是 query 且 是這篇 document 第一次出現\n",
    "        wordSet.append(word)\n",
    "\n",
    "    for word in ddict:\n",
    "        #ddict[word] = ddict[word] / len(Document_dict[FileName])\n",
    "        ddict[word] = ddict[word]\n",
    "    #print(FileName, len(Document_dict[FileName]))\n",
    "    Document_TF[FileName] = ddict\n",
    "\n",
    "#print(Document_TF)\n",
    "#print(Word_Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 計算IDF\n",
    "\n",
    "# Query_IDF = \n",
    "# {\n",
    "#     '301' = \n",
    "#     {\n",
    "#         'intern' = 0.84728 ,\n",
    "#         'organ' = 2.17928 ,\n",
    "#         'crime' = 3.44979\n",
    "#     }\n",
    "#     ...\n",
    "# }\n",
    "\n",
    "Query_IDF = {}\n",
    "TotalCount = len(Query_dict) + len(Document_dict)\n",
    "#print(TotalCount)\n",
    "\n",
    "for word in Word_Count:\n",
    "    numerator = TotalCount - Word_Count[word] + 0.5\n",
    "    denominator = Word_Count[word] + 0.5\n",
    "    idf = numerator / denominator\n",
    "    #print(word,idf)\n",
    "    Query_IDF[word] = math.log10(idf + 1)\n",
    "\n",
    "#print(Query_IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 計算 BM25 分數\n",
    "\n",
    "# 參數\n",
    "Variable_K1 = 0.01\n",
    "Variable_K3 = 1\n",
    "Variable_B = 0.0\n",
    "\n",
    "Score_list = {}\n",
    "# Score_list = \n",
    "# {\n",
    "#     dict '301' = \n",
    "#     {\n",
    "#         'FBIS3-10082' = 0.12345 ,\n",
    "#         'FBIS3-10083' = 0.23456 ,\n",
    "#         ...\n",
    "#     }\n",
    "#     dict '302' = \n",
    "#     {\n",
    "#         'FBIS3-10082' = 0.54321 ,\n",
    "#         'FBIS3-10083' = 0.23456 ,\n",
    "#         ...\n",
    "#     }\n",
    "# }\n",
    "\n",
    "for queryfile in Query_dict:\n",
    "    querylist = Query_dict[queryfile]\n",
    "#   queryfile = '301'    \n",
    "#   querylist = ['intern', 'organ', 'crime']\n",
    "    score_dict = {}\n",
    "\n",
    "    for docfile in Document_dict:\n",
    "        docwordLen = len(Document_dict[docfile])\n",
    "#       docfile = 'FBIS3-10082'\n",
    "#       Document_Count['FBIS3-10082']['intern'] = 1\n",
    "#       docwordLen = 字節長度\n",
    "        score = 0\n",
    "\n",
    "        for term in querylist:\n",
    "            idf = Query_IDF[term]\n",
    "            count = 0\n",
    "            if term in Document_Count[docfile]:\n",
    "                count = Document_Count[docfile][term]\n",
    "\n",
    "            if docwordLen == 0:\n",
    "                docwordLen = 1\n",
    "            tf = count / docwordLen\n",
    "            numerator = idf * tf * (Variable_K1 + 1)\n",
    "            denominator = tf + Variable_K1 * ( 1 - Variable_B + Variable_B * (docwordLen / Variable_AvgWord))\n",
    "            K3 = ((Variable_K3 + 1) * Query_TF[queryfile][term] ) / (Variable_K3 + Query_TF[queryfile][term])\n",
    "\n",
    "            score += (numerator / denominator) * K3\n",
    "        score_dict[docfile] = score\n",
    "        #print(queryfile, docfile, score)\n",
    "    #print(queryfile, score_dict)\n",
    "    Score_list[queryfile] = score_dict\n",
    "#print(Score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 輸出\n",
    "\n",
    "outPath = 'C:/Users/dnc22/IR_HW2/output.txt'\n",
    "\n",
    "with open(outPath, 'w') as f:\n",
    "    f.writelines('Query,RetrievedDocuments\\n')\n",
    "\n",
    "    for querydict in Score_list:\n",
    "        #print(Score_list[querydict])\n",
    "        doc_score = sorted(Score_list[querydict].items(), key=lambda item: item[1] , reverse=True)\n",
    "        #print(querydict , doc_score)\n",
    "        f.writelines(querydict + ',')\n",
    "        for docFileName in doc_score:\n",
    "            f.writelines(docFileName[0])\n",
    "            if docFileName != doc_score[-1]:\n",
    "                f.writelines(' ')\n",
    "        f.writelines('\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94875d2831fb8245c9ec96370e5873570c92cca8cb3c42167be1483abe7892ba"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('IR': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
